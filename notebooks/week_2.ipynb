{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jfpWJ5EPMdDK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNMW-VysOldA"
      },
      "source": [
        "\n",
        "# Load the dataset\n",
        "\n",
        "The dataset from Kaggle doesn't have column headers, so we'll add them.\n",
        "\n",
        "You will need to download 'KDDTrain+.txt' and 'KDDTest+.txt' from the Kaggle link you provided.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dn1GfmT6OgEj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Column names for the dataset\n",
        "columns = [\n",
        "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land',\n",
        "    'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
        "    'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
        "    'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login',\n",
        "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
        "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
        "    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "    'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
        "    'attack', 'difficulty'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mghu5kg1Oi7e"
      },
      "outputs": [],
      "source": [
        "# Load training and testing data\n",
        "train_df = pd.read_csv('./archive (2)/KDDTrain+.txt', header=None, names=columns)\n",
        "test_df = pd.read_csv('./archive (2)/KDDTest+.txt', header=None, names=columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn9Tdzn0O3K9"
      },
      "source": [
        "# --- 1. Data Preprocessing ---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rKWlcX3nOu6r"
      },
      "outputs": [],
      "source": [
        "# Combine train and test sets for consistent preprocessing\n",
        "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yCk0nLQlO7hD"
      },
      "outputs": [],
      "source": [
        "# Identify categorical and numerical columns\n",
        "categorical_cols = ['protocol_type', 'service', 'flag']\n",
        "numerical_cols = [col for col in combined_df.columns if col not in categorical_cols + ['attack', 'difficulty']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eJ5iR80FO-Ma"
      },
      "outputs": [],
      "source": [
        "# Label Encoding for categorical features\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    combined_df[col] = le.fit_transform(combined_df[col])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q4tbFsFzPAuJ"
      },
      "outputs": [],
      "source": [
        "# Create the target variable: 1 for 'attack', 0 for 'normal'\n",
        "combined_df['attack_class'] = combined_df['attack'].apply(lambda x: 0 if x == 'normal' else 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C_C8tJa-PDXA"
      },
      "outputs": [],
      "source": [
        "# Drop the original 'attack' and 'difficulty' columns\n",
        "combined_df = combined_df.drop(columns=['attack', 'difficulty'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8IVWl6DcPFMG"
      },
      "outputs": [],
      "source": [
        "# Separate features (X) and target (y)\n",
        "X = combined_df.drop(columns=['attack_class'])\n",
        "y = combined_df['attack_class']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "k-3MT1sfPGq2"
      },
      "outputs": [],
      "source": [
        "# Scaling numerical features\n",
        "scaler = StandardScaler()\n",
        "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0SAbYjCMPITU"
      },
      "outputs": [],
      "source": [
        "# Split the data back into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u632Ge0PKii"
      },
      "source": [
        "# --- 2. Model Training and Evaluation ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "R8__GymvQZqQ"
      },
      "outputs": [],
      "source": [
        "# Define models and their hyperparameter grids\n",
        "models_and_params = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"model\": LogisticRegression(max_iter=1000, solver='saga'),\n",
        "        \"params\": {\n",
        "            'C': [0.1, 1, 10],\n",
        "            'penalty': ['l1', 'l2']\n",
        "        }\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        \"model\": RandomForestClassifier(random_state=42),\n",
        "        \"params\": {\n",
        "            'n_estimators': [50, 100],\n",
        "            'max_depth': [10, 20]\n",
        "        }\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        \"model\": GradientBoostingClassifier(random_state=42),\n",
        "        \"params\": {\n",
        "            'n_estimators': [50, 100],\n",
        "            'learning_rate': [0.05, 0.1],\n",
        "            'max_depth': [3, 5]\n",
        "        }\n",
        "    },\n",
        "    \"Support Vector Machine (SVM)\": {\n",
        "        \"model\": SVC(probability=True, random_state=42),\n",
        "        \"params\": {\n",
        "            'C': [0.1, 1],\n",
        "            'kernel': ['rbf', 'linear']\n",
        "        }\n",
        "    },\n",
        "    \"K-Nearest Neighbors (KNN)\": {\n",
        "        \"model\": KNeighborsClassifier(),\n",
        "        \"params\": {\n",
        "            'n_neighbors': [3, 5, 7],\n",
        "            'weights': ['uniform', 'distance']\n",
        "        }\n",
        "    },\n",
        "    \"Decision Tree\": {\n",
        "        \"model\": DecisionTreeClassifier(random_state=42),\n",
        "        \"params\": {\n",
        "            'criterion': ['gini', 'entropy'],\n",
        "            'max_depth': [10, 20, None]\n",
        "        }\n",
        "    },\n",
        "    \"Multi-layer Perceptron\": {\n",
        "        \"model\": MLPClassifier(max_iter=500, random_state=42, early_stopping=True),\n",
        "        \"params\": {\n",
        "            'hidden_layer_sizes': [(50,), (100,)],\n",
        "            'activation': ['relu', 'tanh'],\n",
        "            'alpha': [0.0001, 0.001]\n",
        "        }\n",
        "    },\n",
        "    # Naive Bayes has no significant hyperparameters to tune, so we run it directly.\n",
        "    \"Gaussian Naive Bayes\": {\n",
        "        \"model\": GaussianNB(),\n",
        "        \"params\": {}\n",
        "    }\n",
        "}\n",
        "\n",
        "results = {}\n",
        "best_estimators = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "h1IgsSHUQqbA"
      },
      "outputs": [],
      "source": [
        "# To run on the full dataset, use these:\n",
        "X_TRAIN_DATA = X_train\n",
        "Y_TRAIN_DATA = y_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_e2AEAPMQy8r",
        "outputId": "2a5d5820-9390-42bf-b3ca-bcc159311a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Processing: Logistic Regression ---\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\saval\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV Score: 0.9364\n",
            "Best Params: {'C': 1, 'penalty': 'l2'}\n",
            "\n",
            "--- Test Set Evaluation for Logistic Regression ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.92      0.96      0.94     15411\n",
            "      Attack       0.95      0.92      0.93     14293\n",
            "\n",
            "    accuracy                           0.94     29704\n",
            "   macro avg       0.94      0.94      0.94     29704\n",
            "weighted avg       0.94      0.94      0.94     29704\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "--- Processing: Random Forest ---\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "Best CV Score: 0.9955\n",
            "Best Params: {'max_depth': 20, 'n_estimators': 50}\n",
            "\n",
            "--- Test Set Evaluation for Random Forest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.99      1.00      1.00     15411\n",
            "      Attack       1.00      0.99      1.00     14293\n",
            "\n",
            "    accuracy                           1.00     29704\n",
            "   macro avg       1.00      1.00      1.00     29704\n",
            "weighted avg       1.00      1.00      1.00     29704\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "--- Processing: Gradient Boosting ---\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best CV Score: 0.9939\n",
            "Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "\n",
            "--- Test Set Evaluation for Gradient Boosting ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.99      1.00      0.99     15411\n",
            "      Attack       1.00      0.99      0.99     14293\n",
            "\n",
            "    accuracy                           0.99     29704\n",
            "   macro avg       0.99      0.99      0.99     29704\n",
            "weighted avg       0.99      0.99      0.99     29704\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "--- Processing: Support Vector Machine (SVM) ---\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "Best CV Score: 0.9499\n",
            "Best Params: {'C': 1, 'kernel': 'rbf'}\n",
            "\n",
            "--- Test Set Evaluation for Support Vector Machine (SVM) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.93      0.98      0.96     15411\n",
            "      Attack       0.98      0.92      0.95     14293\n",
            "\n",
            "    accuracy                           0.95     29704\n",
            "   macro avg       0.96      0.95      0.95     29704\n",
            "weighted avg       0.95      0.95      0.95     29704\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "--- Processing: K-Nearest Neighbors (KNN) ---\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "Best CV Score: 0.9923\n",
            "Best Params: {'n_neighbors': 3, 'weights': 'distance'}\n",
            "\n",
            "--- Test Set Evaluation for K-Nearest Neighbors (KNN) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.99      0.99      0.99     15411\n",
            "      Attack       0.99      0.99      0.99     14293\n",
            "\n",
            "    accuracy                           0.99     29704\n",
            "   macro avg       0.99      0.99      0.99     29704\n",
            "weighted avg       0.99      0.99      0.99     29704\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "--- Processing: Decision Tree ---\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "Best CV Score: 0.9941\n",
            "Best Params: {'criterion': 'entropy', 'max_depth': 20}\n",
            "\n",
            "--- Test Set Evaluation for Decision Tree ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.99      1.00      1.00     15411\n",
            "      Attack       1.00      0.99      1.00     14293\n",
            "\n",
            "    accuracy                           1.00     29704\n",
            "   macro avg       1.00      1.00      1.00     29704\n",
            "weighted avg       1.00      1.00      1.00     29704\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "--- Processing: Multi-layer Perceptron ---\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best CV Score: 0.9897\n",
            "Best Params: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,)}\n",
            "\n",
            "--- Test Set Evaluation for Multi-layer Perceptron ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.99      0.99      0.99     15411\n",
            "      Attack       0.99      0.99      0.99     14293\n",
            "\n",
            "    accuracy                           0.99     29704\n",
            "   macro avg       0.99      0.99      0.99     29704\n",
            "weighted avg       0.99      0.99      0.99     29704\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "--- Processing: Gaussian Naive Bayes ---\n",
            "\n",
            "--- Test Set Evaluation for Gaussian Naive Bayes ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.86      0.89      0.88     15411\n",
            "      Attack       0.88      0.85      0.86     14293\n",
            "\n",
            "    accuracy                           0.87     29704\n",
            "   macro avg       0.87      0.87      0.87     29704\n",
            "weighted avg       0.87      0.87      0.87     29704\n",
            "\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Perform Grid Search or direct fitting and evaluate the best model\n",
        "for name, mp in models_and_params.items():\n",
        "    print(f\"--- Processing: {name} ---\")\n",
        "\n",
        "    # If there are parameters to tune, use GridSearchCV\n",
        "    if mp['params']:\n",
        "        grid_search = GridSearchCV(mp['model'], mp['params'], cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "        grid_search.fit(X_TRAIN_DATA, Y_TRAIN_DATA)\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        results[name] = {\n",
        "            \"Best CV Score\": grid_search.best_score_,\n",
        "            \"Best Params\": grid_search.best_params_\n",
        "        }\n",
        "        print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
        "        print(f\"Best Params: {grid_search.best_params_}\")\n",
        "\n",
        "    # If no parameters, just fit the model directly\n",
        "    else:\n",
        "        best_model = mp['model']\n",
        "        best_model.fit(X_TRAIN_DATA, Y_TRAIN_DATA)\n",
        "        results[name] = {\n",
        "            \"Best CV Score\": None,\n",
        "            \"Best Params\": \"N/A\"\n",
        "        }\n",
        "\n",
        "    best_estimators[name] = best_model\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Store performance metrics\n",
        "    results[name][\"Accuracy\"] = accuracy_score(y_test, y_pred)\n",
        "    results[name][\"Precision\"] = precision_score(y_test, y_pred, average='weighted')\n",
        "    results[name][\"Recall\"] = recall_score(y_test, y_pred, average='weighted')\n",
        "    results[name][\"F1-Score\"] = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"\\n--- Test Set Evaluation for {name} ---\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Normal', 'Attack']))\n",
        "    print(\"-\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B83ylmWPSnZ"
      },
      "source": [
        "# --- 3. Comparison of Results ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yLauJaQDQ3W4"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame from the detailed results for easy comparison\n",
        "results_summary = {name: {k: v for k, v in res.items() if k not in ['Best Params']} for name, res in results.items()}\n",
        "results_df = pd.DataFrame(results_summary).T.sort_values(by='F1-Score', ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sTlLWKsZQ6KH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- üöÄ Final Model Performance Comparison üöÄ ---\n",
            "                              Best CV Score  Accuracy  Precision    Recall  \\\n",
            "Random Forest                      0.995539  0.995859   0.995866  0.995859   \n",
            "Decision Tree                      0.994066  0.995623   0.995627  0.995623   \n",
            "Gradient Boosting                  0.993932  0.994176   0.994178  0.994176   \n",
            "K-Nearest Neighbors (KNN)          0.992324  0.992459   0.992460  0.992459   \n",
            "Multi-layer Perceptron             0.989656  0.990069   0.990069  0.990069   \n",
            "Support Vector Machine (SVM)       0.949947  0.952936   0.954236  0.952936   \n",
            "Logistic Regression                0.936354  0.936642   0.937081  0.936642   \n",
            "Gaussian Naive Bayes                    NaN  0.871734   0.872102  0.871734   \n",
            "\n",
            "                              F1-Score  \n",
            "Random Forest                 0.995859  \n",
            "Decision Tree                 0.995623  \n",
            "Gradient Boosting             0.994176  \n",
            "K-Nearest Neighbors (KNN)     0.992459  \n",
            "Multi-layer Perceptron        0.990069  \n",
            "Support Vector Machine (SVM)  0.952850  \n",
            "Logistic Regression           0.936581  \n",
            "Gaussian Naive Bayes          0.871593  \n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- üöÄ Final Model Performance Comparison üöÄ ---\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Y0hv3h2sQ7j4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- ‚öôÔ∏è Best Hyperparameters Found ‚öôÔ∏è ---\n",
            "\n",
            "Logistic Regression:\n",
            "  {'C': 1, 'penalty': 'l2'}\n",
            "\n",
            "Random Forest:\n",
            "  {'max_depth': 20, 'n_estimators': 50}\n",
            "\n",
            "Gradient Boosting:\n",
            "  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "\n",
            "Support Vector Machine (SVM):\n",
            "  {'C': 1, 'kernel': 'rbf'}\n",
            "\n",
            "K-Nearest Neighbors (KNN):\n",
            "  {'n_neighbors': 3, 'weights': 'distance'}\n",
            "\n",
            "Decision Tree:\n",
            "  {'criterion': 'entropy', 'max_depth': 20}\n",
            "\n",
            "Multi-layer Perceptron:\n",
            "  {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,)}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- ‚öôÔ∏è Best Hyperparameters Found ‚öôÔ∏è ---\")\n",
        "for name, res in results.items():\n",
        "    if res['Best Params'] != \"N/A\":\n",
        "        print(f\"\\n{name}:\")\n",
        "        print(f\"  {res['Best Params']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
